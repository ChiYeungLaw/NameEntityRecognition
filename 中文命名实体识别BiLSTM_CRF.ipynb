{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "中文命名实体识别BiLSTM-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6OkxipFfw-A",
        "colab_type": "text"
      },
      "source": [
        "# 项目描述："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Rc_BE4fzul",
        "colab_type": "text"
      },
      "source": [
        "在本项目中将利用LSTM和LSTM-CRF实现中文命名实体识别。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbTkW93lnbtl",
        "colab_type": "text"
      },
      "source": [
        "# 加载中文NER数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2pCqXqpfn3z",
        "colab_type": "code",
        "outputId": "8fd81d31-8765-406c-aa74-3f2a849f23e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/ChineseNERData')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hogq0vT9ohzl",
        "colab_type": "code",
        "outputId": "5126882b-c491-481d-89a0-6d094d3aebee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bilstm_crf_zh.pt      source_data.txt\ttest_data.txt\n",
            "bilstm_softmax_zh.pt  source_label.txt\ttest_label.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16cH0AX40PFB",
        "colab_type": "text"
      },
      "source": [
        "句子开始与结束的tags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfAPvUx-0etc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START = '<s>'\n",
        "END = '<e>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAwhvQX5pkit",
        "colab_type": "text"
      },
      "source": [
        "训练集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4cmgIx5omMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('source_data.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "train_text = [line.strip().split(' ') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77M8AQC8pnUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('source_label.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "train_label = [line.strip().split(' ') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRFNe_7Tpm43",
        "colab_type": "text"
      },
      "source": [
        "测试集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLCdbpVVp7hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test_data.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "test_text = [line.strip().split(' ') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzPt9HAIqODq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test_label.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "test_label = [line.strip().split(' ') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWXWyL3pqcCN",
        "colab_type": "text"
      },
      "source": [
        "辅助函数与数据构造："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deWije6iqh9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 词典\n",
        "voc = [word for line in train_text for word in line] + [word for line in test_text for word in line]\n",
        "voc = list(set(voc))\n",
        "# tag集合\n",
        "tagset = [tag for line in train_label for tag in line] + [tag for line in test_label for tag in line] + [START] + [END]\n",
        "tagset = list(set(tagset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiSUDhYLrcfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 单词到index的映射\n",
        "word_to_idx = {word: idx for idx, word in enumerate(voc)}\n",
        "idx_to_word = voc\n",
        "# tag到index的映射\n",
        "tag_to_idx = {tag: idx for idx, tag in enumerate(tagset)}\n",
        "idx_to_tag = tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZQcLPJHr6Ac",
        "colab_type": "text"
      },
      "source": [
        "将原来的数据改为index数据："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ci9Nz-Jr9Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = [[word_to_idx[word] for word in line] for line in train_text]\n",
        "train_y = [[tag_to_idx[tag] for tag in line] for line in train_label]\n",
        "test_x = [[word_to_idx[word] for word in line] for line in test_text]\n",
        "test_y = [[tag_to_idx[tag] for tag in line] for line in test_label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRRfVWl1Qxk7",
        "colab_type": "text"
      },
      "source": [
        "分出测试集和验证集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNZVZVdlQ1Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_data = len(train_x)\n",
        "num_valid = int(num_data * 0.2)\n",
        "valid_x = train_x[:num_valid]\n",
        "valid_y = train_y[:num_valid]\n",
        "train_x = train_x[num_valid:]\n",
        "train_y = train_y[num_valid:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXaQeCNoBrbG",
        "colab_type": "text"
      },
      "source": [
        "# BaseLine模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YvtdDURBumH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "333ede75-23f3-43c9-fae6-ae98679f1f29"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for tag in test_y:\n",
        "    for t in tag:\n",
        "        if t == 4:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "print(f\"BaseLine Test Set Accuracy: {correct/total:.3%}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BaseLine Test Set Accuracy: 85.872%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTW0D6mGsms0",
        "colab_type": "text"
      },
      "source": [
        "# 模型构造"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sSerAess2QY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eesCnOh7eryN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_NER(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_to_idx, embed_dim, hidden_size,\n",
        "                 use_gpu=True, use_crf=True):\n",
        "        super(BiLSTM_NER, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_idx = tag_to_idx\n",
        "        self.tag_size = len(tag_to_idx)\n",
        "        self.use_gpu = use_gpu\n",
        "        self.use_crf = use_crf\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_size,\n",
        "                            bidirectional=True)\n",
        "        self.hidden2Tag = nn.Linear(2 * hidden_size, self.tag_size)\n",
        "        \n",
        "        if use_crf:\n",
        "            self.transitions = nn.Parameter(torch.zeros(self.tag_size, self.tag_size))\n",
        "            self.transitions.data[self.tag_to_idx[START], :] = -10000.0\n",
        "            self.transitions.data[:, self.tag_to_idx[END]] = -10000.0\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        text_embed = self.embed(sentence) # [seq_len, embed_dim]\n",
        "        text_embed = text_embed.unsqueeze(1) # [seq_len, 1, embed_dim]\n",
        "        output, _ = self.lstm(text_embed) # [seq_len, 1, 2 * hidden_size]\n",
        "        output = output.view(len(sentence), 2 * self.hidden_size) # [seq_len, 2 * hidden_size]\n",
        "        lstm_feats = self.hidden2Tag(output) # [seq_len, tag_size]\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        r = torch.LongTensor(range(feats.size()[0]))\n",
        "        if self.use_gpu:\n",
        "            r = r.cuda()\n",
        "            pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_idx[START]]), tags])\n",
        "            pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_idx[END]])])\n",
        "        else:\n",
        "            pad_start_tags = torch.cat([torch.LongTensor([self.tag_to_idx[START]]), tags])\n",
        "            pad_stop_tags = torch.cat([tags, torch.LongTensor([self.tag_to_idx[END]])])\n",
        "        score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(feats[r, tags])\n",
        "        return score\n",
        "    \n",
        "    def _forward_alg(self, feats):\n",
        "        alphas = torch.ones(1, self.tag_size) * (-10000.)\n",
        "        alphas[0, self.tag_to_idx[START]] = 0.\n",
        "        if self.use_gpu:\n",
        "            alphas = alphas.cuda()\n",
        "        for feat in feats:\n",
        "            alphas = alphas + self.transitions + feat.view(-1, 1)\n",
        "            max_alphas, _ = torch.max(alphas, dim=1)\n",
        "            alphas = alphas - max_alphas.view(-1, 1)\n",
        "            alphas = max_alphas + torch.logsumexp(alphas, dim=1).view(1, -1)\n",
        "        alphas = (alphas + self.transitions[self.tag_to_idx[END]]).view(1, -1)\n",
        "        return torch.logsumexp(alphas, dim=-1)\n",
        "    \n",
        "    def viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "        v = torch.ones(1, self.tag_size) * (-10000.0)\n",
        "        v[0, self.tag_to_idx[START]] = 0\n",
        "        if self.use_gpu:\n",
        "            v = v.cuda()\n",
        "        \n",
        "        for feat in feats:\n",
        "            v = v + self.transitions\n",
        "            _, bptrs_t = torch.max(v, dim=1)\n",
        "            bptrs_t = bptrs_t.squeeze(0).data.cpu().numpy()\n",
        "            v = v[range(len(bptrs_t)), bptrs_t] + feat\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        v = v + self.transitions[self.tag_to_idx[END]]\n",
        "        v.data[self.tag_to_idx[END]] = -10000.\n",
        "        v.data[self.tag_to_idx[START]] = -10000.\n",
        "        \n",
        "        best_tag_id = torch.argmax(v.unsqueeze(0)).item()\n",
        "        path_score = v[best_tag_id]\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in backpointers[::-1]:\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_idx[START]\n",
        "        return path_score, best_path[::-1]\n",
        "    \n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        if self.use_crf:\n",
        "            forward_score = self._forward_alg(feats)\n",
        "            score = self._score_sentence(feats, tags)\n",
        "            return forward_score - score\n",
        "        else:\n",
        "            scores = nn.functional.cross_entropy(feats, tags)\n",
        "            return scores\n",
        "    \n",
        "    def forward(self, sentence):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        if self.use_crf:\n",
        "            score, tag_seq = self.viterbi_decode(feats)\n",
        "        else:\n",
        "            score, tag_seq = torch.max(feats, 1)\n",
        "            tag_seq = list(tag_seq.cpu().data)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqjUEsxZB69C",
        "colab_type": "text"
      },
      "source": [
        "# 模型评价与比较"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evjbN6b0A6lb",
        "colab_type": "text"
      },
      "source": [
        "模型评价函数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGxYJH8sVwNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eva(model, data_x, data_y, use_cuda):\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    for sentence, tag in zip(data_x, data_y):\n",
        "        if use_cuda:\n",
        "            sentence = torch.cuda.LongTensor(sentence)\n",
        "        else:\n",
        "            sentence = torch.LongTensor(sentence)\n",
        "        _, tag_seq = model(sentence)\n",
        "        for i in range(len(tag_seq)):\n",
        "            if tag_seq[i] == tag[i]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKUkHkHrA9A3",
        "colab_type": "text"
      },
      "source": [
        "超参数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMWyQPfPjA5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(voc)\n",
        "embed_dim = 100\n",
        "hidden_size = 100\n",
        "learning_rate = 0.01\n",
        "use_gpu = True\n",
        "num_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_vLpbaPBAWJ",
        "colab_type": "text"
      },
      "source": [
        "## BiLSTM-CRF模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zugbEJlHi51H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bilstm_crf = BiLSTM_NER(vocab_size, tag_to_idx, embed_dim, hidden_size,\n",
        "                        use_gpu=use_gpu, use_crf=True).to(device)\n",
        "optimizer_crf = torch.optim.Adam(bilstm_crf.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRWmiT-yBEce",
        "colab_type": "text"
      },
      "source": [
        "模型训练："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l_CqmfTjQF1",
        "colab_type": "code",
        "outputId": "afd0c47b-2709-4d3b-fb96-72380088062f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_valid_acc = 0.\n",
        "print(f\"BiLSTM-CRF Traning Begin.\")\n",
        "for epoch in range(num_epoch):\n",
        "    total_loss = 0.\n",
        "    for i, sentence, tag in zip(range(len(train_x)), train_x, train_y):\n",
        "        sentence = torch.cuda.LongTensor(sentence)\n",
        "        tag = torch.cuda.LongTensor(tag)\n",
        "        optimizer_crf.zero_grad()\n",
        "        loss = bilstm_crf.neg_log_likelihood(sentence, tag)\n",
        "        loss.backward()\n",
        "        optimizer_crf.step()\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"Epoch: {epoch+1}/{num_epoch}. Sentence: {i+1}/{len(train_x)}. Total_loss: {total_loss:.3f}\")\n",
        "    valid_acc = eva(bilstm_crf, valid_x, valid_y, use_gpu)\n",
        "    if valid_acc > best_valid_acc:\n",
        "        torch.save(bilstm_crf.state_dict(), 'bilstm_crf_zh.pt')\n",
        "        print(f\"Valid Acc: {valid_acc:.3%}.\")\n",
        "        print(f\"Epoch: {epoch+1}/{num_epoch}. Total_loss: {total_loss:.2f}\")\n",
        "        best_valid_acc = valid_acc\n",
        "    else:\n",
        "        print(f\"Early Stop!\")\n",
        "        break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiLSTM-CRF Traning Begin.\n",
            "Epoch: 1/10. Sentence: 500/14947. Total_loss: 7027.164\n",
            "Epoch: 1/10. Sentence: 1000/14947. Total_loss: 9950.858\n",
            "Epoch: 1/10. Sentence: 1500/14947. Total_loss: 12525.010\n",
            "Epoch: 1/10. Sentence: 2000/14947. Total_loss: 14693.253\n",
            "Epoch: 1/10. Sentence: 2500/14947. Total_loss: 16961.802\n",
            "Epoch: 1/10. Sentence: 3000/14947. Total_loss: 20533.348\n",
            "Epoch: 1/10. Sentence: 4000/14947. Total_loss: 26961.955\n",
            "Epoch: 1/10. Sentence: 4500/14947. Total_loss: 29840.735\n",
            "Epoch: 1/10. Sentence: 5000/14947. Total_loss: 32655.028\n",
            "Epoch: 1/10. Sentence: 5500/14947. Total_loss: 34434.245\n",
            "Epoch: 1/10. Sentence: 6000/14947. Total_loss: 36415.131\n",
            "Epoch: 1/10. Sentence: 6500/14947. Total_loss: 38361.449\n",
            "Epoch: 1/10. Sentence: 7000/14947. Total_loss: 40410.552\n",
            "Epoch: 1/10. Sentence: 7500/14947. Total_loss: 43107.889\n",
            "Epoch: 1/10. Sentence: 8000/14947. Total_loss: 45153.216\n",
            "Epoch: 1/10. Sentence: 8500/14947. Total_loss: 47061.030\n",
            "Epoch: 1/10. Sentence: 9000/14947. Total_loss: 50150.599\n",
            "Epoch: 1/10. Sentence: 9500/14947. Total_loss: 52716.555\n",
            "Epoch: 1/10. Sentence: 10000/14947. Total_loss: 54818.921\n",
            "Epoch: 1/10. Sentence: 10500/14947. Total_loss: 56757.004\n",
            "Epoch: 1/10. Sentence: 11000/14947. Total_loss: 58409.348\n",
            "Epoch: 1/10. Sentence: 11500/14947. Total_loss: 60122.474\n",
            "Epoch: 1/10. Sentence: 12000/14947. Total_loss: 62954.587\n",
            "Epoch: 1/10. Sentence: 12500/14947. Total_loss: 66095.983\n",
            "Epoch: 1/10. Sentence: 13000/14947. Total_loss: 68397.025\n",
            "Epoch: 1/10. Sentence: 13500/14947. Total_loss: 70437.173\n",
            "Epoch: 1/10. Sentence: 14000/14947. Total_loss: 72201.370\n",
            "Epoch: 1/10. Sentence: 14500/14947. Total_loss: 74226.747\n",
            "Valid Acc: 92.961%.\n",
            "Epoch: 1/10. Total_loss: 76299.49\n",
            "Epoch: 2/10. Sentence: 500/14947. Total_loss: 2083.781\n",
            "Epoch: 2/10. Sentence: 1000/14947. Total_loss: 3853.589\n",
            "Epoch: 2/10. Sentence: 1500/14947. Total_loss: 5942.941\n",
            "Epoch: 2/10. Sentence: 2000/14947. Total_loss: 7824.886\n",
            "Epoch: 2/10. Sentence: 2500/14947. Total_loss: 9928.756\n",
            "Epoch: 2/10. Sentence: 3000/14947. Total_loss: 13066.016\n",
            "Epoch: 2/10. Sentence: 3500/14947. Total_loss: 16246.856\n",
            "Epoch: 2/10. Sentence: 4000/14947. Total_loss: 19438.270\n",
            "Epoch: 2/10. Sentence: 4500/14947. Total_loss: 22408.510\n",
            "Epoch: 2/10. Sentence: 5000/14947. Total_loss: 25279.254\n",
            "Epoch: 2/10. Sentence: 5500/14947. Total_loss: 27027.887\n",
            "Epoch: 2/10. Sentence: 6000/14947. Total_loss: 28870.274\n",
            "Epoch: 2/10. Sentence: 6500/14947. Total_loss: 30713.182\n",
            "Epoch: 2/10. Sentence: 7000/14947. Total_loss: 32695.630\n",
            "Epoch: 2/10. Sentence: 7500/14947. Total_loss: 35429.640\n",
            "Epoch: 2/10. Sentence: 8000/14947. Total_loss: 37409.455\n",
            "Epoch: 2/10. Sentence: 8500/14947. Total_loss: 39433.868\n",
            "Epoch: 2/10. Sentence: 9000/14947. Total_loss: 42283.658\n",
            "Epoch: 2/10. Sentence: 9500/14947. Total_loss: 44728.215\n",
            "Epoch: 2/10. Sentence: 10000/14947. Total_loss: 46655.766\n",
            "Epoch: 2/10. Sentence: 10500/14947. Total_loss: 48541.761\n",
            "Epoch: 2/10. Sentence: 11000/14947. Total_loss: 50231.790\n",
            "Epoch: 2/10. Sentence: 11500/14947. Total_loss: 51962.488\n",
            "Epoch: 2/10. Sentence: 12000/14947. Total_loss: 54756.858\n",
            "Epoch: 2/10. Sentence: 12500/14947. Total_loss: 57840.314\n",
            "Epoch: 2/10. Sentence: 13000/14947. Total_loss: 60153.766\n",
            "Epoch: 2/10. Sentence: 13500/14947. Total_loss: 62182.542\n",
            "Epoch: 2/10. Sentence: 14000/14947. Total_loss: 63934.030\n",
            "Epoch: 2/10. Sentence: 14500/14947. Total_loss: 66161.719\n",
            "Early Stop!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btnLifocpKqR",
        "colab_type": "code",
        "outputId": "297f4cf0-3cba-479b-9608-5dd877d23df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Test Set Accuracy: {eva(bilstm_crf, test_x, test_y, True):.3%}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Set Accuracy: 91.587%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3gBdGJABVHz",
        "colab_type": "text"
      },
      "source": [
        "## BiLSTM-Softmax模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyWcjXt2qOdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bilstm_softmax = BiLSTM_NER(vocab_size, tag_to_idx, embed_dim, hidden_size,\n",
        "                            use_gpu=True, use_crf=False).to(device)\n",
        "optimizer_softmax = torch.optim.Adam(bilstm_softmax.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJt3hr5YBZFI",
        "colab_type": "text"
      },
      "source": [
        "模型训练："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P0WQBMRqgRq",
        "colab_type": "code",
        "outputId": "416e656d-dcba-4ba1-84b8-3253fba99452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_valid_acc = 0.\n",
        "print(f\"BiLSTM-softmax Traning Begin.\")\n",
        "for epoch in range(num_epoch):\n",
        "    total_loss = 0.\n",
        "    for i, sentence, tag in zip(range(len(train_x)), train_x, train_y):\n",
        "        sentence = torch.cuda.LongTensor(sentence)\n",
        "        tag = torch.cuda.LongTensor(tag)\n",
        "        optimizer_softmax.zero_grad()\n",
        "        loss = bilstm_softmax.neg_log_likelihood(sentence, tag)\n",
        "        loss.backward()\n",
        "        optimizer_softmax.step()\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"Epoch: {epoch+1}/{num_epoch}. Sentence: {i+1}/{len(train_x)}. Total_loss: {total_loss:.3f}\")\n",
        "    valid_acc = eva(bilstm_softmax, valid_x, valid_y, use_gpu)\n",
        "    if valid_acc > best_valid_acc:\n",
        "        torch.save(bilstm_softmax.state_dict(), 'bilstm_softmax_zh.pt')\n",
        "        print(f\"Valid Acc: {valid_acc:.3%}.\")\n",
        "        print(f\"Epoch: {epoch+1}/{num_epoch}. Total_loss: {total_loss:.2f}\")\n",
        "        best_valid_acc = valid_acc\n",
        "    else:\n",
        "        print(f\"Early Stop!\")\n",
        "        break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiLSTM-softmax Traning Begin.\n",
            "Epoch: 1/10. Sentence: 500/14947. Total_loss: 184.490\n",
            "Epoch: 1/10. Sentence: 1000/14947. Total_loss: 309.602\n",
            "Epoch: 1/10. Sentence: 1500/14947. Total_loss: 430.790\n",
            "Epoch: 1/10. Sentence: 2000/14947. Total_loss: 528.846\n",
            "Epoch: 1/10. Sentence: 2500/14947. Total_loss: 633.139\n",
            "Epoch: 1/10. Sentence: 3000/14947. Total_loss: 789.079\n",
            "Epoch: 1/10. Sentence: 3500/14947. Total_loss: 939.427\n",
            "Epoch: 1/10. Sentence: 4000/14947. Total_loss: 1080.247\n",
            "Epoch: 1/10. Sentence: 4500/14947. Total_loss: 1195.494\n",
            "Epoch: 1/10. Sentence: 5000/14947. Total_loss: 1317.981\n",
            "Epoch: 1/10. Sentence: 5500/14947. Total_loss: 1400.260\n",
            "Epoch: 1/10. Sentence: 6000/14947. Total_loss: 1499.892\n",
            "Epoch: 1/10. Sentence: 6500/14947. Total_loss: 1590.566\n",
            "Epoch: 1/10. Sentence: 7000/14947. Total_loss: 1696.542\n",
            "Epoch: 1/10. Sentence: 7500/14947. Total_loss: 1815.777\n",
            "Epoch: 1/10. Sentence: 8000/14947. Total_loss: 1917.189\n",
            "Epoch: 1/10. Sentence: 8500/14947. Total_loss: 2025.414\n",
            "Epoch: 1/10. Sentence: 9000/14947. Total_loss: 2154.079\n",
            "Epoch: 1/10. Sentence: 9500/14947. Total_loss: 2268.686\n",
            "Epoch: 1/10. Sentence: 10000/14947. Total_loss: 2361.895\n",
            "Epoch: 1/10. Sentence: 10500/14947. Total_loss: 2451.285\n",
            "Epoch: 1/10. Sentence: 11000/14947. Total_loss: 2522.302\n",
            "Epoch: 1/10. Sentence: 11500/14947. Total_loss: 2607.475\n",
            "Epoch: 1/10. Sentence: 12000/14947. Total_loss: 2743.025\n",
            "Epoch: 1/10. Sentence: 12500/14947. Total_loss: 2885.745\n",
            "Epoch: 1/10. Sentence: 13000/14947. Total_loss: 2984.421\n",
            "Epoch: 1/10. Sentence: 13500/14947. Total_loss: 3096.770\n",
            "Epoch: 1/10. Sentence: 14000/14947. Total_loss: 3176.147\n",
            "Epoch: 1/10. Sentence: 14500/14947. Total_loss: 3278.340\n",
            "Valid Acc: 93.035%.\n",
            "Epoch: 1/10. Total_loss: 3363.01\n",
            "Epoch: 2/10. Sentence: 500/14947. Total_loss: 92.964\n",
            "Epoch: 2/10. Sentence: 1000/14947. Total_loss: 177.474\n",
            "Epoch: 2/10. Sentence: 1500/14947. Total_loss: 278.673\n",
            "Epoch: 2/10. Sentence: 2000/14947. Total_loss: 358.319\n",
            "Epoch: 2/10. Sentence: 2500/14947. Total_loss: 445.210\n",
            "Epoch: 2/10. Sentence: 3000/14947. Total_loss: 587.436\n",
            "Epoch: 2/10. Sentence: 3500/14947. Total_loss: 722.030\n",
            "Epoch: 2/10. Sentence: 4000/14947. Total_loss: 849.928\n",
            "Epoch: 2/10. Sentence: 4500/14947. Total_loss: 959.223\n",
            "Epoch: 2/10. Sentence: 5000/14947. Total_loss: 1072.415\n",
            "Epoch: 2/10. Sentence: 5500/14947. Total_loss: 1155.582\n",
            "Epoch: 2/10. Sentence: 6000/14947. Total_loss: 1246.697\n",
            "Epoch: 2/10. Sentence: 6500/14947. Total_loss: 1334.142\n",
            "Epoch: 2/10. Sentence: 7000/14947. Total_loss: 1434.438\n",
            "Epoch: 2/10. Sentence: 7500/14947. Total_loss: 1552.746\n",
            "Epoch: 2/10. Sentence: 8000/14947. Total_loss: 1639.244\n",
            "Epoch: 2/10. Sentence: 8500/14947. Total_loss: 1738.035\n",
            "Epoch: 2/10. Sentence: 9000/14947. Total_loss: 1861.131\n",
            "Epoch: 2/10. Sentence: 9500/14947. Total_loss: 1974.218\n",
            "Epoch: 2/10. Sentence: 10000/14947. Total_loss: 2065.158\n",
            "Epoch: 2/10. Sentence: 10500/14947. Total_loss: 2153.107\n",
            "Epoch: 2/10. Sentence: 11000/14947. Total_loss: 2220.353\n",
            "Epoch: 2/10. Sentence: 11500/14947. Total_loss: 2300.424\n",
            "Epoch: 2/10. Sentence: 12000/14947. Total_loss: 2432.436\n",
            "Epoch: 2/10. Sentence: 12500/14947. Total_loss: 2570.070\n",
            "Epoch: 2/10. Sentence: 13000/14947. Total_loss: 2667.668\n",
            "Epoch: 2/10. Sentence: 13500/14947. Total_loss: 2777.812\n",
            "Epoch: 2/10. Sentence: 14000/14947. Total_loss: 2851.032\n",
            "Epoch: 2/10. Sentence: 14500/14947. Total_loss: 2944.770\n",
            "Valid Acc: 93.313%.\n",
            "Epoch: 2/10. Total_loss: 3020.81\n",
            "Epoch: 3/10. Sentence: 500/14947. Total_loss: 89.519\n",
            "Epoch: 3/10. Sentence: 1000/14947. Total_loss: 172.181\n",
            "Epoch: 3/10. Sentence: 1500/14947. Total_loss: 271.183\n",
            "Epoch: 3/10. Sentence: 2000/14947. Total_loss: 352.478\n",
            "Epoch: 3/10. Sentence: 2500/14947. Total_loss: 442.479\n",
            "Epoch: 3/10. Sentence: 3000/14947. Total_loss: 581.818\n",
            "Epoch: 3/10. Sentence: 3500/14947. Total_loss: 715.347\n",
            "Epoch: 3/10. Sentence: 4000/14947. Total_loss: 843.582\n",
            "Epoch: 3/10. Sentence: 4500/14947. Total_loss: 950.748\n",
            "Epoch: 3/10. Sentence: 5000/14947. Total_loss: 1062.516\n",
            "Epoch: 3/10. Sentence: 5500/14947. Total_loss: 1145.184\n",
            "Epoch: 3/10. Sentence: 6000/14947. Total_loss: 1236.946\n",
            "Epoch: 3/10. Sentence: 6500/14947. Total_loss: 1324.773\n",
            "Epoch: 3/10. Sentence: 7000/14947. Total_loss: 1424.777\n",
            "Epoch: 3/10. Sentence: 7500/14947. Total_loss: 1543.559\n",
            "Epoch: 3/10. Sentence: 8000/14947. Total_loss: 1634.820\n",
            "Epoch: 3/10. Sentence: 8500/14947. Total_loss: 1733.573\n",
            "Epoch: 3/10. Sentence: 9000/14947. Total_loss: 1856.746\n",
            "Epoch: 3/10. Sentence: 9500/14947. Total_loss: 1963.677\n",
            "Epoch: 3/10. Sentence: 10000/14947. Total_loss: 2057.518\n",
            "Epoch: 3/10. Sentence: 10500/14947. Total_loss: 2152.275\n",
            "Epoch: 3/10. Sentence: 11000/14947. Total_loss: 2217.562\n",
            "Epoch: 3/10. Sentence: 11500/14947. Total_loss: 2296.059\n",
            "Epoch: 3/10. Sentence: 12000/14947. Total_loss: 2429.426\n",
            "Epoch: 3/10. Sentence: 12500/14947. Total_loss: 2568.552\n",
            "Epoch: 3/10. Sentence: 13000/14947. Total_loss: 2667.388\n",
            "Epoch: 3/10. Sentence: 13500/14947. Total_loss: 2779.462\n",
            "Epoch: 3/10. Sentence: 14000/14947. Total_loss: 2849.587\n",
            "Epoch: 3/10. Sentence: 14500/14947. Total_loss: 2941.726\n",
            "Valid Acc: 93.386%.\n",
            "Epoch: 3/10. Total_loss: 3020.79\n",
            "Epoch: 4/10. Sentence: 500/14947. Total_loss: 88.424\n",
            "Epoch: 4/10. Sentence: 1000/14947. Total_loss: 172.121\n",
            "Epoch: 4/10. Sentence: 1500/14947. Total_loss: 271.765\n",
            "Epoch: 4/10. Sentence: 2000/14947. Total_loss: 352.425\n",
            "Epoch: 4/10. Sentence: 2500/14947. Total_loss: 439.376\n",
            "Epoch: 4/10. Sentence: 3000/14947. Total_loss: 580.548\n",
            "Epoch: 4/10. Sentence: 3500/14947. Total_loss: 714.252\n",
            "Epoch: 4/10. Sentence: 4000/14947. Total_loss: 844.548\n",
            "Epoch: 4/10. Sentence: 4500/14947. Total_loss: 951.329\n",
            "Epoch: 4/10. Sentence: 5000/14947. Total_loss: 1067.545\n",
            "Epoch: 4/10. Sentence: 5500/14947. Total_loss: 1145.853\n",
            "Epoch: 4/10. Sentence: 6000/14947. Total_loss: 1236.263\n",
            "Epoch: 4/10. Sentence: 6500/14947. Total_loss: 1326.617\n",
            "Epoch: 4/10. Sentence: 7000/14947. Total_loss: 1430.082\n",
            "Epoch: 4/10. Sentence: 7500/14947. Total_loss: 1546.916\n",
            "Epoch: 4/10. Sentence: 8000/14947. Total_loss: 1642.328\n",
            "Epoch: 4/10. Sentence: 8500/14947. Total_loss: 1740.536\n",
            "Epoch: 4/10. Sentence: 9000/14947. Total_loss: 1870.621\n",
            "Epoch: 4/10. Sentence: 9500/14947. Total_loss: 1973.093\n",
            "Epoch: 4/10. Sentence: 10000/14947. Total_loss: 2066.928\n",
            "Epoch: 4/10. Sentence: 10500/14947. Total_loss: 2157.400\n",
            "Epoch: 4/10. Sentence: 11000/14947. Total_loss: 2221.764\n",
            "Epoch: 4/10. Sentence: 11500/14947. Total_loss: 2300.293\n",
            "Epoch: 4/10. Sentence: 12000/14947. Total_loss: 2432.046\n",
            "Epoch: 4/10. Sentence: 12500/14947. Total_loss: 2570.000\n",
            "Epoch: 4/10. Sentence: 13000/14947. Total_loss: 2673.330\n",
            "Epoch: 4/10. Sentence: 13500/14947. Total_loss: 2786.629\n",
            "Epoch: 4/10. Sentence: 14000/14947. Total_loss: 2858.676\n",
            "Epoch: 4/10. Sentence: 14500/14947. Total_loss: 2942.266\n",
            "Early Stop!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2H5ygo515IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58478449-0165-46f7-bdb9-a2e2db63be60"
      },
      "source": [
        "print(f\"Test Set Accuracy: {eva(bilstm_softmax, test_x, test_y, True):.3%}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Set Accuracy: 92.049%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vm7nXp2CcFl",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXBdrUHUCePB",
        "colab_type": "text"
      },
      "source": [
        "模型准确率比较为："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k55ZVLqhCdZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "740207e8-f4c4-4f56-ccba-0dd548911881"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(data=[0.85872, 0.92049, 0.91587], index=['Baseline', 'BiLSTM', 'BiLSTM-CRF'], columns=['Test Set Acc'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Set Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.85872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BiLSTM</th>\n",
              "      <td>0.92049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BiLSTM-CRF</th>\n",
              "      <td>0.91587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Test Set Acc\n",
              "Baseline         0.85872\n",
              "BiLSTM           0.92049\n",
              "BiLSTM-CRF       0.91587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}